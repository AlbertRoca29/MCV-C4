{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Lab 1: Planar transformations and image rectification\n",
    "\n",
    "The two main goals of this first lab are the following:\n",
    "\n",
    "1) Get more familiar with the hierarchy of 2D transformations. <br>\n",
    "\n",
    "2) Image rectification: Removal of the projective distortion of an image of a planar object.\n",
    "\n",
    "This notebook combines some text cells (Markdown cells) and code cells. Some parts of the code need to be completed. All tasks you need to complete are marked in <span style='color:LightGreen'> LightGreen.  </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## **1. Image transformations**\n",
    "\n",
    "In this first part of the lab you will apply different types of 2D transformations to a given image. For that, you first need to create a function that applies a homography to an image.\n",
    "\n",
    "<span style='color:LightGreen'> - Create the function  *apply_H* that gets as input a homography and\n",
    "an image and returns the image transformed by the homography. </span>\n",
    "\n",
    "Note: The size of the transformed image has to be automatically set so that it contains the whole transformed image.\n",
    "You will need to interpolate the image values at some points, for that,\n",
    "you may use the function *scipy.ndimage.map_coordinates*"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from PIL import Image, ImageDraw\n",
    "import numpy as np\n",
    "from scipy.ndimage import map_coordinates\n",
    "from numpy import linalg as LA\n",
    "from utils import line_draw, plot_img\n",
    "\n",
    "# Translations are not visible !!!\n",
    "\n",
    "def apply_H(Image, Homography):\n",
    "    \n",
    "    h, w = Image.shape[:2]\n",
    "\n",
    "    # Corners in homogeneous coordinates\n",
    "    corners = np.array([[     0, w - 1,     0,  w - 1],\n",
    "                        [     0,     0, h - 1,  h - 1],\n",
    "                        [     1,     1,     1,      1]\n",
    "                        ])\n",
    "    \n",
    "    # Transform corners to find output image bounds\n",
    "    transformed_corners = Homography @ corners\n",
    "    transformed_corners /= transformed_corners[2] \n",
    "\n",
    "    # Compute the output image's size\n",
    "    min_x, min_y = np.floor(transformed_corners[:2].min(axis=1)).astype(int)\n",
    "    max_x, max_y = np.ceil(transformed_corners[:2].max(axis=1)).astype(int)\n",
    "    out_w, out_h = max_x - min_x,  max_y - min_y\n",
    "\n",
    "    # Create a grid of coordinates in the output image space\n",
    "    x, y = np.meshgrid(np.arange(out_w) + min_x, np.arange(out_h) + min_y)\n",
    "    coords = np.stack([x.ravel(), y.ravel(), np.ones_like(x.ravel())])\n",
    "    \n",
    "    # Map coordinates back to input image using *inverse homography*\n",
    "    inv_H = LA.inv(Homography)\n",
    "    src_coords = inv_H @ coords\n",
    "    src_coords /= src_coords[2] \n",
    "\n",
    "    # Interpolate pixel values\n",
    "    map_x, map_y = src_coords[0].reshape(out_h, out_w), src_coords[1].reshape(out_h, out_w)\n",
    "    transformed = [\n",
    "        map_coordinates(Image[..., c], [map_y, map_x], order=1, mode='constant', cval=0)\n",
    "        for c in range(3)\n",
    "    ]\n",
    "    return np.stack(transformed, axis=-1)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### **1.1 Similarities**\n",
    "\n",
    "<span style='color:LightGreen'> - Complete the code below by generating a matrix H that produces a similarity transformation. </span>"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from math import pi\n",
    "\n",
    "theta = pi/6 # angle\n",
    "s = .5 # scale\n",
    "tx = 1000; ty = 0 # translation (NOT VISIBLE)\n",
    "\n",
    "H_Similarity = np.array([\n",
    "            [s * np.cos(theta),     -s * np.sin(theta),      tx],\n",
    "            [s * np.sin(theta),      s * np.cos(theta),      ty],\n",
    "            [                0,                      0,       1]\n",
    "        ])\n",
    "\n",
    "img_path = \"./Data/0005_s.png\"\n",
    "I = Image.open(img_path)\n",
    "I_sim = apply_H(np.array(I), H_Similarity)\n",
    "plot_img(I)\n",
    "plot_img(I_sim)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1.2 Affinities**\n",
    "\n",
    "<span style='color:LightGreen'> - Complete the code below by generating a matrix H that produces an affine transformation.  </span>\n",
    "\n",
    "<span style='color:LightGreen'> - Decompose the affinity in four transformations: two\n",
    "rotations, a scale, and a translation (you may use function *numpy.linalg.svd* for that).  </span>\n",
    "\n",
    "<span style='color:LightGreen'> - Verify that the product of the four previous transformations\n",
    "produces the same matrix H as above.  </span>"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Parameters\n",
    "theta, phi = np.pi / 9, np.pi / 12      # Rotation angles\n",
    "sx, sy = 0.75, 0.5                       # Scaling factors\n",
    "tx, ty = 300, 200                       # Translation values (NOT VISIBLE)\n",
    "\n",
    "# Rotation matrices\n",
    "R1 = np.array([[np.cos(theta), -np.sin(theta)], \n",
    "               [np.sin(theta),  np.cos(theta)]])  \n",
    "\n",
    "R2 = np.array([[np.cos(phi), -np.sin(phi)], \n",
    "               [np.sin(phi),  np.cos(phi)]])     \n",
    "\n",
    "# Scaling matrix\n",
    "S = np.diag([sx, sy]) \n",
    "\n",
    "# Combine transformations\n",
    "A = R2 @ S @ R1  \n",
    "\n",
    "# Affine matrix with translation\n",
    "H_Affinity = np.eye(3)\n",
    "H_Affinity[:2, :2] = A\n",
    "H_Affinity[:2, 2] = [tx, ty]\n",
    "\n",
    "I_aff = apply_H(np.array(I), H_Affinity)\n",
    "\n",
    "plot_img(I)\n",
    "plot_img(I_aff)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "<span style='color:LightGreen'> - Verify that the proper sequence of the four previous\n",
    "transformations, applied over the image `I` **one by one**, produces the same transformed image as before.  </span>"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Rotation matrix 1\n",
    "R1 = np.array([[np.cos(theta), -np.sin(theta), 0], \n",
    "               [np.sin(theta),  np.cos(theta), 0],\n",
    "               [            0,              0, 1]])\n",
    "I_aff_R1 = apply_H(np.array(I), R1)\n",
    "\n",
    "# Scale matrix\n",
    "S = np.array([[sx,  0,  0], \n",
    "              [ 0, sy,  0], \n",
    "              [ 0,  0,  1]])\n",
    "I_aff_R1_S = apply_H(I_aff_R1, S)\n",
    "\n",
    "# Rotation matrix 2\n",
    "R2 = np.array([[np.cos(phi), -np.sin(phi), 0], \n",
    "               [np.sin(phi),  np.cos(phi), 0],\n",
    "               [          0,            0, 1]])\n",
    "I_aff_R1_S_R2 = apply_H(I_aff_R1_S, R2)\n",
    "\n",
    "# Translation matrix\n",
    "T = np.array([[1, 0, tx], \n",
    "              [0, 1, ty], \n",
    "              [0, 0,  1]]).astype(float)\n",
    "I_aff = apply_H(I_aff_R1_S_R2, T)\n",
    "\n",
    "# Plot the results at each step\n",
    "plot_img(I)\n",
    "plot_img(I_aff_R1)\n",
    "plot_img(I_aff_R1_S)\n",
    "plot_img(I_aff_R1_S_R2)\n",
    "plot_img(I_aff)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "As we can see there's a small discrepancy as the absolute coordinates are used when we've already scaled the image. We can achieve the exact same results by removing the empty rows and cols."
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "I_aff = I_aff[I_aff.any(axis=(1,2)), :, :]\n",
    "I_aff = I_aff[:, I_aff.any(axis=(0,2)), :]\n",
    "\n",
    "plot_img(I_aff)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1.3 Projective transformations (Homographies)**\n",
    "\n",
    "<span style='color:LightGreen'> - Complete the code below by generating a matrix H that produces a projective transformation.  </span>"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Parameters for projective transformation\n",
    "h11, h12, h13 = 1.5, 0.2, -0.5    # can the parameters be explained in a simple way?\n",
    "h21, h22, h23 = 0.3, 1.1, 0.2   \n",
    "h31, h32, h33 = 0.001, 0.002, 1  \n",
    "\n",
    "# Define the projective transformation matrix\n",
    "H_projective = np.array([\n",
    "    [h11, h12, h13],\n",
    "    [h21, h22, h23],\n",
    "    [h31, h32, h33]\n",
    "])\n",
    "\n",
    "I_proj = apply_H(np.array(I), H_projective)\n",
    "\n",
    "plot_img(I)\n",
    "plot_img(I_proj)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2. Affine Rectification**\n",
    "\n",
    "This step is needed in order to rectify an image in a stratified way, where we first perform affine rectification (current section) and then metric rectification (Section 3).\n",
    "\n",
    "### **2.1 Vanishing points estimated semi-automatically**\n",
    "\n",
    "First, we will perform affine rectification by computing the vanishing points in a semi-automatic way. Line segments in the image will be detected automatically and then pairs of segments corresponding to imaged parallel lines will be manually selected. The segments are detected by the Line Segment Detector algorithm (paper [1], demo and code available in [2]). The result of this algorithm in the images of interest is already provided. The initial and final points of each detected segment are provided in a text file. The code below shows how to read the corresponding points for a certain segment given its index.  \n",
    "\n",
    "[1] R. Grompone von Gioi, J. Jakubowicz, J.-M. Morel, G. Randall. LSD: a Line Segment Detector. , Image Processing On Line, 2, , pp. 35–55, 2012.\n",
    "\n",
    "[2] http://www.ipol.im/pub/art/2012/gjmr-lsd/"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# load images and lines\n",
    "img_path = \"./Data/0000_s.png\"\n",
    "I = Image.open(img_path)\n",
    "img2_path = \"./Data/0000_s_lines.jpg\"\n",
    "Il = Image.open(img2_path)\n",
    "#plot_img(Il)\n",
    "\n",
    "lines_path = \"./Data/0000_s_info_lines.txt\"\n",
    "A = np.loadtxt(lines_path)\n",
    "\n",
    "# points of interest\n",
    "i = 423 # line index (starting from 0)\n",
    "p1 = [A[i, 0], A[i, 1], 1] # initial point in line i\n",
    "p2 = [A[i, 2], A[i, 3], 1] # final point in line i\n",
    "i = 239\n",
    "p3 = [A[i, 0], A[i, 1], 1]\n",
    "p4 = [A[i, 2], A[i, 3], 1]\n",
    "i = 711\n",
    "p5 = [A[i, 0], A[i, 1], 1]\n",
    "p6 = [A[i, 2], A[i, 3], 1]\n",
    "i = 564\n",
    "p7 = [A[i, 0], A[i, 1], 1]\n",
    "p8 = [A[i, 2], A[i, 3], 1]\n",
    "\n",
    "points = [p1, p2, p3, p4, p5, p6, p7, p8]\n",
    "points = [np.array(p) for p in points]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "<span style='color:LightGreen'> - Compute the lines l1, l2, l3, l4, that pass through the different pairs of points.  </span>"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "l1 = np.cross(points[0], points[1])  # Line between points[0] and points[1]\n",
    "l2 = np.cross(points[2], points[3])  # Line between points[2] and points[3]\n",
    "l3 = np.cross(points[4], points[5])  # Line between points[4] and points[5]\n",
    "l4 = np.cross(points[6], points[7])  # Line between points[6] and points[7]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# show the chosen lines in the image\n",
    "canv = ImageDraw.Draw(I)\n",
    "line_draw(l1, canv, I.size)\n",
    "line_draw(l2, canv, I.size)\n",
    "line_draw(l3, canv, I.size)\n",
    "line_draw(l4, canv, I.size)\n",
    "\n",
    "# The displayed lines will alter image I so we have to reopen the original image after the plot\n",
    "plot_img(I)\n",
    "I = Image.open(img_path)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "cell_type": "markdown",
   "source": "<span style='color:LightGreen'> - Compute the homography that affinely rectifies the image. </span>"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Compute intersection points using cross product of lines\n",
    "p_infinity1 = np.cross(l1, l2)  # Intersection of l1 and l2\n",
    "p_infinity2 = np.cross(l3, l4)  # Intersection of l3 and l4\n",
    "\n",
    "# Normalize the intersection points to make them homogeneous\n",
    "p_infinity1 /= p_infinity1[2]\n",
    "p_infinity2 /= p_infinity2[2]\n",
    "\n",
    "# Construct the homography\n",
    "l_inf = np.cross(p_infinity1, p_infinity2)\n",
    "H = np.eye(3)\n",
    "H[2] = l_inf / l_inf[2] \n",
    "\n",
    "I_aff_01 = apply_H(np.array(I), H)\n",
    "plot_img(I)\n",
    "plot_img(I_aff_01)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "<span style='color:LightGreen'> - Compute the transformed lines lr1, lr2, lr3, lr4 and\n",
    "      show the transformed lines in the transformed image. </span>"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def transform_line(line, H):\n",
    "    \"\"\"Transform a line using the homography matrix.\"\"\"\n",
    "    H_inv = np.linalg.inv(H)  # Inverse of the homography\n",
    "    line_transformed = np.dot(H_inv.T, line)  # Transform the line\n",
    "    return line_transformed / np.linalg.norm(line_transformed[:2])\n",
    "\n",
    "lr1 = transform_line(l1, H)\n",
    "lr2 = transform_line(l2, H)\n",
    "lr3 = transform_line(l3, H)\n",
    "lr4 = transform_line(l4, H)\n",
    "\n",
    "I_aff = Image.fromarray(I_aff_01)\n",
    "canv = ImageDraw.Draw(I_aff)\n",
    "line_draw(lr1, canv, I_aff.size)\n",
    "line_draw(lr2, canv, I_aff.size)\n",
    "line_draw(lr3, canv, I_aff.size)\n",
    "line_draw(lr4, canv, I_aff.size)\n",
    "\n",
    "# The displayed lines will alter image I so we have to reopen the original image after the plot\n",
    "plot_img(I_aff)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "<span style='color:LightGreen'> - To evaluate the results, compute the angle between the different pair \n",
    "      of lines before and after the image transformation. </span>"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import math\n",
    "def angle_between_lines(line1, line2):\n",
    "    \"\"\"Compute the angle between two lines.\"\"\"\n",
    "    # Extract coefficients\n",
    "    a1, b1, _ = line1\n",
    "    a2, b2, _ = line2\n",
    "\n",
    "    # Compute the dot product and magnitudes\n",
    "    dot_product = a1 * a2 + b1 * b2\n",
    "    magnitude1 = np.sqrt(a1**2 + b1**2)\n",
    "    magnitude2 = np.sqrt(a2**2 + b2**2)\n",
    "\n",
    "    # Compute the cosine of the angle\n",
    "    cos_theta = dot_product / (magnitude1 * magnitude2)\n",
    "    cos_theta = np.clip(cos_theta, -1.0, 1.0)  # Clip to avoid numerical issues\n",
    "\n",
    "    # Compute the angle in radians and then convert to degrees\n",
    "    theta = math.acos(cos_theta)\n",
    "    return math.degrees(theta)\n",
    "\n",
    "# Original lines\n",
    "angles_before = {\n",
    "    \"l1_l2\": angle_between_lines(l1, l2),\n",
    "    \"l3_l4\": angle_between_lines(l3, l4),\n",
    "}\n",
    "\n",
    "# Transformed lines\n",
    "angles_after = {\n",
    "    \"lr1_lr2\": angle_between_lines(lr1, lr2),\n",
    "    \"lr3_lr4\": angle_between_lines(lr3, lr4),\n",
    "}\n",
    "\n",
    "# Display results\n",
    "print(\"Angles before transformation:\", angles_before)\n",
    "print(\"Angles after transformation:\", angles_after)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "<span style='color:LightGreen'> - Verify, experimentally, that the cross-ratio is preserved after the image rectification (you may choose the endpoints of some detected line segments). </span>"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### **2.2 Vanishing points estimated automatically** \n",
    "\n",
    "The vanishing points in an image can be estimated automatically. In this lab, we will use the orthogonal vanishing points estimated by the technique proposed in [3] (code available in [4]), which actually uses the line segments estimated with the LSD algorithm [1] used before.\n",
    "\n",
    "In this section, we will work with the image 'friends.jpeg'. The estimated vanishing points obtained by [3] are provided in the file 'friends_vps.out' (see code below for more details).\n",
    "\n",
    "[3] Xiaohu Lu, Jian Yao, Haoang Li, Yahui Liu. 2-Line Exhaustive Searching for Real-Time Vanishing Point Estimation in Manhattan World. IEEE/CVF Winter Conference on Applications of Computer Vision (WACV), 2017.\n",
    "\n",
    "[4] https://github.com/rayryeng/XiaohuLuVPDetection\n",
    "\n",
    "<span style='color:LightGreen'> - Perform affine rectification of this image using the appropriate vanishing points automatically detected. **Justify your choice** of vanishing points. </span>"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Visualize image 'friends.jpeg'\n",
    "img_path = \"./Data/friends.jpeg\"\n",
    "I = Image.open(img_path)\n",
    "plot_img(I)\n",
    "# Visualize image 'friends_vps.jpeg' which shows the different line segments detected by LSD [1] and groups\n",
    "# them in three different colors according to the different vanishing points they have been associated.\n",
    "img2_path = \"./Data/friends_vps.jpeg\"\n",
    "Ivp = Image.open(img2_path)\n",
    "plot_img(Ivp)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Load the three orthogonal vanishing points from image 'friends.jpeg' (estimated by [3,4])\n",
    "vps = np.loadtxt('./Data/friends_vps.out', delimiter=',')\n",
    "print(vps)\n",
    "# 'vps' is a numpy array where each row is a vanishing point and each column is a coordinate.\n",
    "# The first, second and third rows in 'vps' correspond to the vanishing points corresponding to,\n",
    "# respectively, red, LightGreen, and blue directions."
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "p_blue= [vps[2, 0], vps[2, 1], 1]\n",
    "p_red = [vps[0, 0], vps[0, 1], 1]\n",
    "\n",
    "l_inf = np.cross(p_blue, p_red)\n",
    "\n",
    "# Construct the homography\n",
    "H = np.eye(3)\n",
    "H[2] = l_inf / l_inf[2] \n",
    "\n",
    "I_aff = apply_H(np.array(I), H)\n",
    "plot_img(I)\n",
    "plot_img(I_aff)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## **3. Metric Rectification**\n",
    "\n",
    "### **3.1 Metric rectification after the affine rectification (stratified solution)**\n",
    "\n",
    "We will work with image 0000.\n",
    "\n",
    "<span style='color:LightGreen'> - Write the code that performs the metric rectification (after the affine rectification). </span>\n",
    "\n",
    "As qualitative evaluation method you can display the images (before and after the metric rectification) with the chosen lines printed on it.\n",
    "      \n",
    "<span style='color:LightGreen'> - Compute the angles between the pair of lines before and after rectification. Comment the result. </span>\n",
    "\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def compute_symmetric_matrix(orthogonal_pairs):\n",
    "    \"\"\"Compute the symmetric matrix S from two pairs of orthogonal lines.\"\"\"\n",
    "    A = []\n",
    "    b = []\n",
    "\n",
    "    for l, m in orthogonal_pairs:\n",
    "        # Equation: (l1*m1, l1*m2 + l2*m1) * [s11, s12] = -l2*m2\n",
    "        A.append([l[0] * m[0], l[0] * m[1] + l[1] * m[0]])\n",
    "        b.append(-l[1] * m[1])\n",
    "\n",
    "    A = np.array(A)\n",
    "    b = np.array(b)\n",
    "\n",
    "    # Solve for [s11, s12]\n",
    "    s = np.linalg.lstsq(A, b, rcond=None)[0]\n",
    "    s11, s12 = s\n",
    "    S = np.array([[s11, s12], [s12, 1]])  # Construct the symmetric matrix S\n",
    "    return S\n",
    "\n",
    "def compute_affine_transform(S):\n",
    "    \"\"\"Compute the affine transform matrix H2 from S.\"\"\"\n",
    "    # Eigen-decomposition: S = U D U^T\n",
    "    eigvals, eigvecs = np.linalg.eigh(S)\n",
    "    \n",
    "    D = np.diag(np.sqrt(eigvals)) # Square root of eigenvalues\n",
    "    A = eigvecs @ D @ eigvecs.T    # A = U sqrt(D) U^T\n",
    "    return A"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "lr1 /= np.linalg.norm(lr1[2])\n",
    "lr2 /= np.linalg.norm(lr2[2])\n",
    "lr3 /= np.linalg.norm(lr3[2])\n",
    "lr4 /= np.linalg.norm(lr4[2])\n",
    "\n",
    "orthogonal_pairs = [\n",
    "    (np.array([lr1[0], lr1[1], lr1[2]]), np.array([lr2[0], lr2[1], lr2[2]])),  # Pair 1\n",
    "    (np.array([lr3[0], lr3[1], lr3[2]]), np.array([lr4[0], lr4[1], lr4[2]]))   # Pair 2\n",
    "]\n",
    "\n",
    "# Step 1: Compute S\n",
    "S = compute_symmetric_matrix(orthogonal_pairs)\n",
    "\n",
    "# Step 2: Compute A\n",
    "A = compute_affine_transform(S)\n",
    "\n",
    "# Step 3: Form H2\n",
    "H2 = np.eye(3)\n",
    "H2[:2, :2] = A\n",
    "H2 = np.linalg.inv(H2)\n",
    "\n",
    "I_metric = apply_H(np.array(I_aff_01), H2)\n",
    "lm1 = transform_line(lr1, H2)\n",
    "lm2 = transform_line(lr2, H2)\n",
    "lm3 = transform_line(lr3, H2)\n",
    "lm4 = transform_line(lr4, H2)\n",
    "\n",
    "I_metric= Image.fromarray(I_metric)\n",
    "canv = ImageDraw.Draw(I_metric)\n",
    "point_color = (0, 0, 255)\n",
    "line_draw(lm1, canv, I_metric.size)\n",
    "line_draw(lm2, canv, I_metric.size)\n",
    "line_draw(lm3, canv, I_metric.size)\n",
    "line_draw(lm4, canv, I_metric.size)\n",
    "\n",
    "plot_img(I_metric)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "angles_before = {\n",
    "    \"l1_l2\": angle_between_lines(l1, l2),\n",
    "    \"l3_l4\": angle_between_lines(l3, l3),\n",
    "}\n",
    "\n",
    "# Transformed lines\n",
    "angles_after = {\n",
    "    \"lm1_lm3\": angle_between_lines(lm1, lm2),\n",
    "    \"lm3_lm4\": angle_between_lines(lm3, lm4),\n",
    "}\n",
    "\n",
    "# Display results\n",
    "print(\"Angles before transformation:\", angles_before)\n",
    "print(\"Angles after transformation:\", angles_after)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## **4. Affine and Metric Rectification of the left facade of image 0001**\n",
    "\n",
    "<span style='color:LightGreen'> - Write the code that rectifies the left facade of image 0001 with\n",
    "      the stratified method.  </span>\n",
    "      \n",
    "Note: For a better visualization of the result crop the initial image so that only the left facade is visible.\n",
    "\n",
    "<span style='color:LightGreen'> - Show the (properly) transformed lines that are used in every step.  </span>\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "img_path = \"./Data/0001_s.png\"\n",
    "I = Image.open(img_path)\n",
    "I = I.crop((0, 0, 500, I.height))\n",
    "img2_path = \"./Data/0001_s_lines.jpg\"\n",
    "Il = Image.open(img2_path)\n",
    "plot_img(I)\n",
    "\n",
    "lines_path = \"./Data/0001_s_info_lines.txt\"\n",
    "A = np.loadtxt(lines_path)\n",
    "\n",
    "# points of interest\n",
    "i = 613 # line index (starting from 0)\n",
    "p1 = [A[i, 0], A[i, 1], 1] # initial point in line i\n",
    "p2 = [A[i, 2], A[i, 3], 1] # final point in line i\n",
    "i = 158\n",
    "p3 = [A[i, 0], A[i, 1], 1]\n",
    "p4 = [A[i, 2], A[i, 3], 1]\n",
    "i = 540\n",
    "p5 = [A[i, 0], A[i, 1], 1]\n",
    "p6 = [A[i, 2], A[i, 3], 1]\n",
    "i = 644\n",
    "p7 = [A[i, 0], A[i, 1], 1]\n",
    "p8 = [A[i, 2], A[i, 3], 1]\n",
    "\n",
    "\n",
    "points = [p1, p2, p3, p4, p5, p6, p7, p8]\n",
    "points = [np.array(p) for p in points]\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def find_intersection(line1, line2):\n",
    "    # Line 1: a1*x + b1*y + c1 = 0\n",
    "    # Line 2: a2*x + b2*y + c2 = 0\n",
    "    a1, b1, c1 = line1\n",
    "    a2, b2, c2 = line2\n",
    "    \n",
    "    # Create the coefficient matrix and the constants vector\n",
    "    A = np.array([[a1, b1], [a2, b2]])\n",
    "    B = np.array([-c1, -c2])\n",
    "    \n",
    "    # Solve the system of linear equations\n",
    "    intersection = np.linalg.solve(A, B)\n",
    "    intersection = [intersection[0], intersection[1], 1]\n",
    "    \n",
    "    return intersection\n",
    "\n",
    "\n",
    "# Find intersection\n",
    "intersection_point1 = find_intersection(l1, l3)\n",
    "intersection_point2 = find_intersection(l2, l4)\n",
    "intersection_point3 = find_intersection(l1, l4)\n",
    "intersection_point4 = find_intersection(l2, l3)\n",
    "\n",
    "l1 = np.cross(points[0], points[1])  # Line between points[0] and points[1]\n",
    "l2 = np.cross(points[2], points[3])  # Line between points[2] and points[3]\n",
    "l3 = np.cross(points[4], points[5])  # Line between points[4] and points[5]\n",
    "l4 = np.cross(points[6], points[7])  # Line between points[6] and points[7]\n",
    "l5 = np.cross(intersection_point1, intersection_point2)  # Line between points[6] and points[7]\n",
    "l6 = np.cross(intersection_point3, intersection_point4)  # Line between points[6] and points[7]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# show the chosen lines in the image\n",
    "canv = ImageDraw.Draw(I)\n",
    "point_color = (0, 0, 255)\n",
    "line_draw(l1, canv, I.size)\n",
    "line_draw(l2, canv, I.size)\n",
    "line_draw(l3, canv, I.size)\n",
    "line_draw(l4, canv, I.size)\n",
    "line_draw(l5, canv, I.size)\n",
    "line_draw(l6, canv, I.size)\n",
    "\n",
    "\n",
    "# The displayed lines will alter image I so we have to reopen the original image after the plot\n",
    "plot_img(I)\n",
    "I = Image.open(img_path)\n",
    "\n",
    "print(type(l1))\n",
    "I = Image.open(img_path)\n",
    "I = I.crop((0, 0, 500, I.height))\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Compute intersection points using cross product of lines\n",
    "p_infinity1 = np.cross(l1, l2)  # Intersection of l1 and l2\n",
    "p_infinity2 = np.cross(l3, l4)  # Intersection of l3 and l4\n",
    "\n",
    "\n",
    "# Normalize the intersection points to make them homogeneous\n",
    "p_infinity1 /= p_infinity1[2]\n",
    "p_infinity2 /= p_infinity2[2]\n",
    "\n",
    "\n",
    "l_inf = np.cross(p_infinity1, p_infinity2)\n",
    "\n",
    "# Construct the homography\n",
    "H = np.eye(3)\n",
    "H[2] = l_inf / l_inf[2] \n",
    "\n",
    "I_aff_01 = apply_H(np.array(I), H)\n",
    "plot_img(I_aff_01)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "\n",
    "lr1 /= np.linalg.norm(lr1[2])\n",
    "lr3 /= np.linalg.norm(lr3[2])\n",
    "lr5 /= np.linalg.norm(lr5[2])\n",
    "lr6 /= np.linalg.norm(lr6[2])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "orthogonal_pairs = [\n",
    "    (np.array([lr1[0], lr1[1], lr1[2]]), np.array([lr3[0], lr3[1], lr3[2]])),  # Pair 1\n",
    "    (np.array([lr5[0], lr5[1], lr5[2]]), np.array([lr6[0], lr6[1], lr6[2]]))   # Pair 2\n",
    "]\n",
    "\n",
    "S = compute_symmetric_matrix(orthogonal_pairs)\n",
    "\n",
    "# Step 2: Compute A\n",
    "A = compute_affine_transform(S)\n",
    "\n",
    "# Step 3: Form H2\n",
    "H2 = np.eye(3)\n",
    "H2[:2, :2] = A\n",
    "H2 = np.linalg.inv(H2)\n",
    "\n",
    "\n",
    "I_metric = apply_H(np.array(I_aff_01), H2)\n",
    "\n",
    "\n",
    "s_x = 1239 / 967\n",
    "s_y = 1736 / 1188\n",
    "\n",
    "\n",
    "\n",
    "lm1 = transform_line(lr1, H2)\n",
    "lm2 = transform_line(lr2, H2)\n",
    "lm3 = transform_line(lr3, H2)\n",
    "lm4 = transform_line(lr4, H2)\n",
    "lm5 = transform_line(lr5, H2)\n",
    "lm6 = transform_line(lr6, H2)\n",
    "\n",
    "'''\n",
    "lm1 = [lm1[0]*s_x, lm1[1]*s_y, lm1[2]* np.sqrt(s_x**2 + s_y**2)]\n",
    "lm2 = [lm2[0]*s_x, lm2[1]*s_y, lm1[2]* np.sqrt(s_x**2 + s_y**2)]\n",
    "lm3 = [lm3[0]*s_x, lm3[1]*s_y, lm1[2]* np.sqrt(s_x**2 + s_y**2)]\n",
    "lm4 = [lm4[0]*s_x, lm4[1]*s_y, lm1[2]* np.sqrt(s_x**2 + s_y**2)]\n",
    "lm5 = [lm5[0]*s_x, lm5[1]*s_y, lm5[2]* np.sqrt(s_x**2 + s_y**2)]\n",
    "lm6 = [lm6[0]*s_x, lm6[1]*s_y, lm6[2]* np.sqrt(s_x**2 + s_y**2)]\n",
    "'''\n",
    "    \n",
    "\n",
    "I_metric= Image.fromarray(I_metric)\n",
    "canv = ImageDraw.Draw(I_metric)\n",
    "point_color = (0, 0, 255)\n",
    "line_draw(lm1, canv, I_metric.size)\n",
    "line_draw(lm2, canv, I_metric.size)\n",
    "line_draw(lm3, canv, I_metric.size)\n",
    "line_draw(lm4, canv, I_metric.size)\n",
    "line_draw(lm5, canv, I_metric.size)\n",
    "line_draw(lm6, canv, I_metric.size)\n",
    "\n",
    "print(lm1)\n",
    "\n",
    "print(I_metric.size)\n",
    "plot_img(I_metric)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## **5. OPTIONAL: Metric Rectification in a single step**\n",
    "\n",
    "<span style='color:LightGreen'> - Write the code that performs metric rectification of the white facade of image 0000 in a single step (algorithm pages 55-57, Hartley-Zisserman book). </span>\n",
    "\n",
    "Note: Use 5 pairs of orthogonal lines. You may consider that windows are square."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
