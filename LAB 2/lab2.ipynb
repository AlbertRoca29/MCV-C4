{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 2: Homography estimation and applications\n",
    "\n",
    "In this lab you will learn how to estimate a homography relating two images given a set of correspondences between them. Then, you will work with different computer vision applications of the homography.\n",
    "\n",
    "More precisely, the goals are:\n",
    "\n",
    "1) Homography estimation with the DLT algorithm. <br>\n",
    "\n",
    "2) Application: Image mosaics. <br>\n",
    "\n",
    "3) Refinement of the estimated homography with the Gold Standard algorithm. <br>\n",
    "\n",
    "4) Application: Camera calibration with a planar pattern and augmented reality. <br>\n",
    "\n",
    "5) Application: Logo detection. <br>\n",
    "\n",
    "6) Application: Logo replacement.\n",
    "\n",
    "The following file combines some text cells (Markdown cells) and code cells. Some parts of the code need to be completed. All tasks you need to complete are marked in <span style='color:Green'> green.  </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "cd \"LAB 2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import math\n",
    "import sys\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "from operator import itemgetter\n",
    "from utils import apply_H_fixed_image_size, plot_img, Ransac_DLT_homography"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **1. Homography estimation with the DLT algorithm**\n",
    "\n",
    "### **1.1 Compute image correspondences**\n",
    "Execute the following code to find image correspondences using ORB [1] (you may also use SIFT, SURF, etc)\n",
    "\n",
    "[1] Ethan Rublee, Vincent Rabaud, Kurt Konolige, Gary R. Bradski: ORB: An efficient alternative to SIFT or SURF. ICCV 2011: 2564-2571."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def get_matches(img1, img2, img3, ratio_threshold=0.85):\n",
    "    \"\"\"\n",
    "    Computes the good matches between three images (img1, img2, img3) using ORB and the ratio test.\n",
    "    \n",
    "    Args:\n",
    "        img1: The first image.\n",
    "        img2: The second image.\n",
    "        img3: The third image.\n",
    "        ratio_threshold: The threshold to apply for the ratio test.\n",
    "    \n",
    "    Returns:\n",
    "        good_matches_12: The list of good matches between img1 and img2.\n",
    "        good_matches_23: The list of good matches between img2 and img3.\n",
    "        kp1, kp2, kp3: Keypoints from the first, second, and third images.\n",
    "    \"\"\"\n",
    "    # Initiate ORB detector\n",
    "    orb = cv2.ORB_create()\n",
    "    \n",
    "    # Find the keypoints and descriptors with ORB\n",
    "    kp1, des1 = orb.detectAndCompute(img1, None)\n",
    "    kp2, des2 = orb.detectAndCompute(img2, None)\n",
    "    kp3, des3 = orb.detectAndCompute(img3, None)\n",
    "    \n",
    "    # Keypoint matching\n",
    "    bf = cv2.BFMatcher()\n",
    "\n",
    "    # Matching between img1 and img2\n",
    "    matches_12 = bf.knnMatch(des1, des2, k=2)\n",
    "    good_matches_12 = []\n",
    "    for m, n in matches_12:\n",
    "        if m.distance < ratio_threshold * n.distance:\n",
    "            good_matches_12.append([m])\n",
    "\n",
    "    # Matching between img2 and img3\n",
    "    matches_23 = bf.knnMatch(des2, des3, k=2)\n",
    "    good_matches_23 = []\n",
    "    for m, n in matches_23:\n",
    "        if m.distance < ratio_threshold * n.distance:\n",
    "            good_matches_23.append([m])\n",
    "\n",
    "    return good_matches_12, good_matches_23, kp1, kp2, kp3\n",
    "\n",
    "# Example usage for 3 images\n",
    "img1 = cv2.imread('Data/llanes/llanes_a.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "img2 = cv2.imread('Data/llanes/llanes_b.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "img3 = cv2.imread('Data/llanes/llanes_c.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "good_matches_12, good_matches_23, kp1, kp2, kp3 = get_matches(img1, img2, img3)\n",
    "\n",
    "# Show \"good\" matches between img1 and img2\n",
    "img_12 = cv2.drawMatchesKnn(img1, kp1, img2, kp2, good_matches_12, None, flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)\n",
    "plt.imshow(img_12)\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(18.5, 10.5)\n",
    "plt.show()\n",
    "\n",
    "# Show \"good\" matches between img2 and img3\n",
    "img_23 = cv2.drawMatchesKnn(img2, kp2, img3, kp3, good_matches_23, None, flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)\n",
    "plt.imshow(img_23)\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(18.5, 10.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1.2 Compute the homography (DLT algorithm) between image pairs**\n",
    "\n",
    "The following cell of code calls the 'Ransac_DLT_homography' function from utils.py\n",
    "Before running the code of the cell you first need to complete some functions in utils.py that are called from 'Ransac_DLT_homography' function:\n",
    "\n",
    "<span style='color:Green'> - Complete the 'DLT_homography' function that computes a homography from a set of point correspondences with the DLT algorithm.  </span>\n",
    "\n",
    "<span style='color:Green'> - Complete the 'Inliers' function that, given a homography, a set of point correspondences and a certain threshold  returns the indices of the correspondences that are inliers.  </span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_homography(kp1, kp2, good_matches, th = 3, max_it = 1000):\n",
    "    \"\"\"\n",
    "    Computes the homography between two images given keypoints and matches.\n",
    "    \n",
    "    Args:\n",
    "        kp1: Keypoints from the first image.\n",
    "        kp2: Keypoints from the second image.\n",
    "        good_matches: List of good matches between the images.\n",
    "    \n",
    "    Returns:\n",
    "        H: The computed homography matrix.\n",
    "        inlier_matches: List of inlier matches.\n",
    "    \"\"\"\n",
    "    points1 = []\n",
    "    points2 = []\n",
    "    \n",
    "    # Extract points from the good matches\n",
    "    for m in good_matches:\n",
    "        points1.append([kp1[m[0].queryIdx].pt[0], kp1[m[0].queryIdx].pt[1], 1])\n",
    "        points2.append([kp2[m[0].trainIdx].pt[0], kp2[m[0].trainIdx].pt[1], 1])\n",
    "    \n",
    "    points1 = np.asarray(points1).T\n",
    "    points2 = np.asarray(points2).T\n",
    "    \n",
    "    # Compute homography using RANSAC\n",
    "    H, indices_inlier_matches = Ransac_DLT_homography(points1, points2, th, max_it)\n",
    "    \n",
    "    # Get inlier matches\n",
    "    inlier_matches = itemgetter(*indices_inlier_matches)(good_matches)\n",
    "    \n",
    "    return H, inlier_matches\n",
    "\n",
    "# Example usage for homography between images 1 and 2\n",
    "H_12, inlier_matches_12 = get_homography(kp1, kp2, good_matches_12)\n",
    "\n",
    "# Visualize matches for image 1 and 2\n",
    "img_12 = cv2.drawMatchesKnn(img1, kp1, img2, kp2, inlier_matches_12, None, flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)\n",
    "plt.imshow(img_12)\n",
    "fig = matplotlib.pyplot.gcf()\n",
    "fig.set_size_inches(18.5, 10.5)\n",
    "plt.show()\n",
    "\n",
    "# Example usage for homography between images 2 and 3\n",
    "H_23, inlier_matches_23 = get_homography(kp2, kp3, good_matches_23)\n",
    "\n",
    "# Visualize matches for image 2 and 3\n",
    "img_23 = cv2.drawMatchesKnn(img2, kp2, img3, kp3, inlier_matches_23, None, flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)\n",
    "plt.imshow(img_23)\n",
    "fig = matplotlib.pyplot.gcf()\n",
    "fig.set_size_inches(18.5, 10.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2. Application: Image mosaics**\n",
    "\n",
    "Now that the homographies relating the images have been estimated we can create a mosaic by properly transforming and fusing the different image contents.\n",
    "For that we create a big enough canvas where the mosaic will be created. The function 'apply_H_fixed_image_size' is provided in utils.py, it is a variant of the 'apply_H' function from lab 1 where this time the size of the transformed is fixed and given as an extra input.\n",
    "\n",
    "<span style='color:Green'> - Complete the 2nd input argument to the 'apply_H_fixed_image_size' function in order to get the image mosaic. </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1 = cv2.imread('Data/llanes/llanes_a.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "img2 = cv2.imread('Data/llanes/llanes_b.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "img3 = cv2.imread('Data/llanes/llanes_c.jpg', cv2.IMREAD_GRAYSCALE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_matches_12, good_matches_23, kp1, kp2, kp3 = get_matches(img1, img2, img3)\n",
    "\n",
    "img_12 = cv2.drawMatchesKnn(img1, kp1, img2, kp2, good_matches_12, None, flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)\n",
    "plt.imshow(img_12)\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(18.5, 10.5)\n",
    "plt.show()\n",
    "\n",
    "img_23 = cv2.drawMatchesKnn(img2, kp2, img3, kp3, good_matches_23, None, flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)\n",
    "plt.imshow(img_23)\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(18.5, 10.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "H_12, inlier_matches_12 = get_homography(kp1, kp2, good_matches_12, th=1)\n",
    "H_23, inlier_matches_23 = get_homography(kp2, kp3, good_matches_23, th=1)\n",
    "print(len(inlier_matches_12), len(inlier_matches_23))\n",
    "\n",
    "img_12 = cv2.drawMatchesKnn(img1, kp1, img2, kp2, inlier_matches_12, None, flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)\n",
    "plt.imshow(img_12)\n",
    "fig = matplotlib.pyplot.gcf()\n",
    "fig.set_size_inches(18.5, 10.5)\n",
    "plt.show()\n",
    "\n",
    "img_23 = cv2.drawMatchesKnn(img2, kp2, img3, kp3, inlier_matches_23, None, flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)\n",
    "plt.imshow(img_23)\n",
    "fig = matplotlib.pyplot.gcf()\n",
    "fig.set_size_inches(18.5, 10.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corners = [-400, 1200, -100, 650] # corners of the canvas where the mosaic will be created\n",
    "\n",
    "img1c = cv2.imread('Data/llanes/llanes_a.jpg', cv2.IMREAD_COLOR)\n",
    "img2c = cv2.imread('Data/llanes/llanes_b.jpg', cv2.IMREAD_COLOR)\n",
    "img3c = cv2.imread('Data/llanes/llanes_c.jpg', cv2.IMREAD_COLOR)\n",
    "img1c = cv2.cvtColor(img1c, cv2.COLOR_BGR2RGB)\n",
    "img2c = cv2.cvtColor(img2c, cv2.COLOR_BGR2RGB)\n",
    "img3c = cv2.cvtColor(img3c, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "img1c_w = apply_H_fixed_image_size(img1c, H_12, corners) # complete the call to the function\n",
    "img2c_w = apply_H_fixed_image_size(img2c, np.eye(3), corners) # complete the call to the function\n",
    "img3c_w = apply_H_fixed_image_size(img3c, np.linalg.inv(H_23), corners) # complete the call to the function\n",
    "\n",
    "img_mosaic = np.maximum(img3c_w,np.maximum(img1c_w,img2c_w))\n",
    "plot_img(img_mosaic)\n",
    "fig = matplotlib.pyplot.gcf()\n",
    "fig.set_size_inches(18.5, 10.5)\n",
    "img_mosaic = cv2.cvtColor(img_mosaic, cv2.COLOR_RGB2BGR)\n",
    "cv2.imwrite('mosaic_llanes.png', img_mosaic) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='color:Green'> - Compute the mosaic with images from folder 'castle_int'. </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1 = cv2.imread('Data/castle_int/0014_s.png', cv2.IMREAD_GRAYSCALE)\n",
    "img2 = cv2.imread('Data/castle_int/0015_s.png', cv2.IMREAD_GRAYSCALE)\n",
    "img3 = cv2.imread('Data/castle_int/0016_s.png', cv2.IMREAD_GRAYSCALE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_matches_12, good_matches_23, kp1, kp2, kp3 = get_matches(img1, img2, img3)\n",
    "\n",
    "img_12 = cv2.drawMatchesKnn(img1, kp1, img2, kp2, good_matches_12, None, flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)\n",
    "plt.imshow(img_12)\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(18.5, 10.5)\n",
    "plt.show()\n",
    "\n",
    "img_23 = cv2.drawMatchesKnn(img2, kp2, img3, kp3, good_matches_23, None, flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)\n",
    "plt.imshow(img_23)\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(18.5, 10.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "H_12, inlier_matches_12 = get_homography(kp1, kp2, good_matches_12, th=10)\n",
    "H_23, inlier_matches_23 = get_homography(kp2, kp3, good_matches_23, th=10)\n",
    "print(len(inlier_matches_12), len(inlier_matches_23))\n",
    "\n",
    "img_12 = cv2.drawMatchesKnn(img1, kp1, img2, kp2, inlier_matches_12, None, flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)\n",
    "plt.imshow(img_12)\n",
    "fig = matplotlib.pyplot.gcf()\n",
    "fig.set_size_inches(18.5, 10.5)\n",
    "plt.show()\n",
    "\n",
    "img_23 = cv2.drawMatchesKnn(img2, kp2, img3, kp3, inlier_matches_23, None, flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)\n",
    "plt.imshow(img_23)\n",
    "fig = matplotlib.pyplot.gcf()\n",
    "fig.set_size_inches(18.5, 10.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corners = [-400, 1200, -100, 650] # corners of the canvas where the mosaic will be created\n",
    "\n",
    "img1c = cv2.imread('Data/castle_int/0014_s.png', cv2.IMREAD_COLOR)\n",
    "img2c = cv2.imread('Data/castle_int/0015_s.png', cv2.IMREAD_COLOR)\n",
    "img3c = cv2.imread('Data/castle_int/0016_s.png', cv2.IMREAD_COLOR)\n",
    "img1c = cv2.cvtColor(img1c, cv2.COLOR_BGR2RGB)\n",
    "img2c = cv2.cvtColor(img2c, cv2.COLOR_BGR2RGB)\n",
    "img3c = cv2.cvtColor(img3c, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "img1c_w = apply_H_fixed_image_size(img1c, H_12, corners) # complete the call to the function\n",
    "img2c_w = apply_H_fixed_image_size(img2c, np.eye(3), corners) # complete the call to the function\n",
    "img3c_w = apply_H_fixed_image_size(img3c, np.linalg.inv(H_23), corners) # complete the call to the function\n",
    "\n",
    "img_mosaic = np.maximum(img3c_w,np.maximum(img1c_w,img2c_w))\n",
    "plot_img(img_mosaic)\n",
    "fig = matplotlib.pyplot.gcf()\n",
    "fig.set_size_inches(18.5, 10.5)\n",
    "img_mosaic = cv2.cvtColor(img_mosaic, cv2.COLOR_RGB2BGR)\n",
    "cv2.imwrite('mosaic_castle_int.png', img_mosaic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='color:Green'> - Compute the mosaic with images from folder 'aerial'. </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1 = cv2.imread('Data/aerial/frame_00001.tif', cv2.IMREAD_GRAYSCALE)\n",
    "img2 = cv2.imread('Data/aerial/frame_00018.tif', cv2.IMREAD_GRAYSCALE)\n",
    "img3 = cv2.imread('Data/aerial/frame_00030.tif', cv2.IMREAD_GRAYSCALE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_matches_12, good_matches_23, kp1, kp2, kp3 = get_matches(img1, img2, img3, ratio_threshold=0.95)\n",
    "\n",
    "img_12 = cv2.drawMatchesKnn(img1, kp1, img2, kp2, good_matches_12, None, flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)\n",
    "plt.imshow(img_12)\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(18.5, 10.5)\n",
    "plt.show()\n",
    "\n",
    "img_23 = cv2.drawMatchesKnn(img2, kp2, img3, kp3, good_matches_23, None, flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)\n",
    "plt.imshow(img_23)\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(18.5, 10.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "H_12, inlier_matches_12 = get_homography(kp1, kp2, good_matches_12, th=10)\n",
    "H_23, inlier_matches_23 = get_homography(kp2, kp3, good_matches_23, th=10)\n",
    "print(len(inlier_matches_12), len(inlier_matches_23))\n",
    "\n",
    "img_12 = cv2.drawMatchesKnn(img1, kp1, img2, kp2, inlier_matches_12, None, flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)\n",
    "plt.imshow(img_12)\n",
    "fig = matplotlib.pyplot.gcf()\n",
    "fig.set_size_inches(18.5, 10.5)\n",
    "plt.show()\n",
    "\n",
    "img_23 = cv2.drawMatchesKnn(img2, kp2, img3, kp3, inlier_matches_23, None, flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)\n",
    "plt.imshow(img_23)\n",
    "fig = matplotlib.pyplot.gcf()\n",
    "fig.set_size_inches(18.5, 10.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corners = [-400, 1200, -100, 650] # corners of the canvas where the mosaic will be created\n",
    "\n",
    "img1c = cv2.imread('Data/aerial/frame_00001.tif', cv2.IMREAD_COLOR)\n",
    "img2c = cv2.imread('Data/aerial/frame_00018.tif', cv2.IMREAD_COLOR)\n",
    "img3c = cv2.imread('Data/aerial/frame_00030.tif', cv2.IMREAD_COLOR)\n",
    "img1c = cv2.cvtColor(img1c, cv2.COLOR_BGR2RGB)\n",
    "img2c = cv2.cvtColor(img2c, cv2.COLOR_BGR2RGB)\n",
    "img3c = cv2.cvtColor(img3c, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "img1c_w = apply_H_fixed_image_size(img1c, H_12, corners) # complete the call to the function\n",
    "img2c_w = apply_H_fixed_image_size(img2c, np.eye(3), corners) # complete the call to the function\n",
    "img3c_w = apply_H_fixed_image_size(img3c, np.linalg.inv(H_23), corners) # complete the call to the function\n",
    "\n",
    "img_mosaic = np.maximum(img3c_w,np.maximum(img1c_w,img2c_w))\n",
    "plot_img(img_mosaic)\n",
    "fig = matplotlib.pyplot.gcf()\n",
    "fig.set_size_inches(18.5, 10.5)\n",
    "img_mosaic = cv2.cvtColor(img_mosaic, cv2.COLOR_RGB2BGR)\n",
    "cv2.imwrite('mosaic_castle_int.png', img_mosaic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='color:Green'> - Compute the mosaic with 5 images from folder 'ny'. </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1 = cv2.imread('Data/ny/NYs1.jpeg', cv2.IMREAD_GRAYSCALE)\n",
    "img2 = cv2.imread('Data/ny/NYs2.jpeg', cv2.IMREAD_GRAYSCALE)\n",
    "img3 = cv2.imread('Data/ny/NYs3.jpeg', cv2.IMREAD_GRAYSCALE)  # we will project onto image 3\n",
    "img4 = cv2.imread('Data/ny/NYs4.jpeg', cv2.IMREAD_GRAYSCALE)\n",
    "img5 = cv2.imread('Data/ny/NYs5.jpeg', cv2.IMREAD_GRAYSCALE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_matches_13, good_matches_32, kp1, kp3, kp2 = get_matches(img1, img3, img2, ratio_threshold=0.95)\n",
    "good_matches_43, good_matches_35, kp4, kp3, kp5 = get_matches(img4, img3, img5, ratio_threshold=0.95)\n",
    "\n",
    "img_13 = cv2.drawMatchesKnn(img1, kp1, img2, kp2, good_matches_13, None, flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)\n",
    "plt.imshow(img_13)\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(18.5, 10.5)\n",
    "plt.show()\n",
    "\n",
    "img_32 = cv2.drawMatchesKnn(img3, kp3, img2, kp2, good_matches_32, None, flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)\n",
    "plt.imshow(img_32)\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(18.5, 10.5)\n",
    "plt.show()\n",
    "\n",
    "img_43 = cv2.drawMatchesKnn(img4, kp4, img3, kp3, good_matches_43, None, flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)\n",
    "plt.imshow(img_43)\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(18.5, 10.5)\n",
    "plt.show()\n",
    "\n",
    "img_35 = cv2.drawMatchesKnn(img3, kp3, img5, kp5, good_matches_35, None, flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)\n",
    "plt.imshow(img_35)\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(18.5, 10.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "H_13, inlier_matches_13 = get_homography(kp1, kp3, good_matches_13, th=10)\n",
    "H_32, inlier_matches_32 = get_homography(kp3, kp2, good_matches_32, th=10)\n",
    "H_43, inlier_matches_43 = get_homography(kp4, kp3, good_matches_43, th=10)\n",
    "H_35, inlier_matches_35 = get_homography(kp3, kp5, good_matches_35, th=10)\n",
    "\n",
    "img_13 = cv2.drawMatchesKnn(img1, kp1, img2, kp2, inlier_matches_13, None, flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)\n",
    "plt.imshow(img_13)\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(18.5, 10.5)\n",
    "plt.show()\n",
    "\n",
    "img_32 = cv2.drawMatchesKnn(img3, kp3, img2, kp2, inlier_matches_32, None, flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)\n",
    "plt.imshow(img_32)\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(18.5, 10.5)\n",
    "plt.show()\n",
    "\n",
    "img_43 = cv2.drawMatchesKnn(img4, kp4, img3, kp3, inlier_matches_43, None, flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)\n",
    "plt.imshow(img_43)\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(18.5, 10.5)\n",
    "plt.show()\n",
    "\n",
    "img_35 = cv2.drawMatchesKnn(img3, kp3, img5, kp5, inlier_matches_35, None, flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)\n",
    "plt.imshow(img_35)\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(18.5, 10.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corners = [-1000, 2000, -400, 800] # corners of the canvas where the mosaic will be created\n",
    "\n",
    "img1c = cv2.imread('Data/ny/NYs1.jpeg', cv2.IMREAD_COLOR)\n",
    "img2c = cv2.imread('Data/ny/NYs2.jpeg', cv2.IMREAD_COLOR)\n",
    "img3c = cv2.imread('Data/ny/NYs3.jpeg', cv2.IMREAD_COLOR)  # we will project onto image 3\n",
    "img4c = cv2.imread('Data/ny/NYs4.jpeg', cv2.IMREAD_COLOR)\n",
    "img5c = cv2.imread('Data/ny/NYs5.jpeg', cv2.IMREAD_COLOR)\n",
    "img1c = cv2.cvtColor(img1c, cv2.COLOR_BGR2RGB)\n",
    "img2c = cv2.cvtColor(img2c, cv2.COLOR_BGR2RGB)\n",
    "img3c = cv2.cvtColor(img3c, cv2.COLOR_BGR2RGB)\n",
    "img4c = cv2.cvtColor(img4c, cv2.COLOR_BGR2RGB)\n",
    "img5c = cv2.cvtColor(img5c, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "img1c_w = apply_H_fixed_image_size(img1c, H_13, corners) # complete the call to the function\n",
    "img2c_w = apply_H_fixed_image_size(img2c, np.linalg.inv(H_32), corners) # complete the call to the function\n",
    "img3c_w = apply_H_fixed_image_size(img3c, np.eye(3), corners) # complete the call to the function\n",
    "img4c_w = apply_H_fixed_image_size(img4c, H_43, corners) # complete the call to the function\n",
    "img5c_w = apply_H_fixed_image_size(img5c, np.linalg.inv(H_35), corners) # complete the call to the function\n",
    "\n",
    "img_mosaic = np.maximum(img5c_w,np.maximum(img4c_w,np.maximum(img3c_w,np.maximum(img1c_w,img2c_w))))\n",
    "plot_img(img_mosaic)\n",
    "fig = matplotlib.pyplot.gcf()\n",
    "fig.set_size_inches(18.5, 10.5)\n",
    "img_mosaic = cv2.cvtColor(img_mosaic, cv2.COLOR_RGB2BGR)\n",
    "cv2.imwrite('mosaic_castle_int.png', img_mosaic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='color:Green'> - In the report, comment the results in every of the four cases: hypothetise why it works or does not work </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **3. Refinement of the estimated homography with the Gold Standard algorithm**\n",
    "\n",
    "In order to refine the previous estimated homography we can minimize the geometric error with the Levenberg-Marquardt algorithm. For that we will call the function 'least_squares' with the proper input arguments that you have to complete. First, it is recommended to read the documentation of that function:\n",
    "\n",
    "https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.least_squares.html\n",
    "\n",
    "Notice that the first input is a function that only provides the vector of the residuals. The algorithm constructs the cost function as a sum of squares of the residuals. In our case the function is called 'geometric_error_terms' and you need to complete it.\n",
    "\n",
    "More precisely, the tasks to perform are:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='color:Green'> - Complete the function 'geometric_error_terms'. </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import least_squares\n",
    "\n",
    "def geometric_error_terms(variables, data_points):  \n",
    "    # Extract the homography from the flattened variables\n",
    "    H = variables.reshape(3, 3)\n",
    "    \n",
    "    # Extract points from data_points\n",
    "    points1 = data_points[0]  # Points from the first image (N, 2)\n",
    "    points2 = data_points[1]  # Points from the second image (N, 2)\n",
    "    \n",
    "    # Convert points1 to homogeneous coordinates (N, 3)\n",
    "    points1_homog = np.hstack((points1, np.ones((points1.shape[0], 1))))  # (N, 3)\n",
    "    \n",
    "    # Transform points1 using the homography H to get the corresponding points in image 2\n",
    "    points1_transformed = np.dot(points1_homog, H.T)  # (N, 3)\n",
    "    \n",
    "    # Normalize the transformed points (convert back from homogeneous coordinates)\n",
    "    points1_transformed /= points1_transformed[:, 2:3]  # Normalize by the z-component\n",
    "    \n",
    "    # Calculate residuals (difference between transformed points and target points)\n",
    "    residuals = points1_transformed[:, :2] - points2\n",
    "    \n",
    "    # Flatten the residuals into a single array to return\n",
    "    return residuals.flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='color:Green'> - Complete the code before calling function 'geometric_error_terms' in order to create the proper input of variables, 'variables0', to pass to the function. </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "H_12_initial = H_12.copy()\n",
    "variables0 = H_12_initial.flatten()\n",
    "points1 = np.array([kp.pt for kp in kp1])\n",
    "points2 = np.array([kp.pt for kp in kp2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='color:Green'> - Extract the refined homogaphy and the refined keypoint locations from the output, 'result', of function 'geometric_error_terms'.  </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = least_squares(geometric_error_terms, variables0, method='lm', args=([points1, points2], ))\n",
    "H_12_refined = result.x.reshape(3, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='color:Green'> - To better compare the two homographies (refined and non refined) compute and print the geometric error before and after the refinement. </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate and print the geometric error before and after the refinement\n",
    "# Initial error\n",
    "points1_homog = np.hstack((points1, np.ones((points1.shape[0], 1))))  # Convert to homogeneous coordinates (500, 3)\n",
    "points1_transformed_initial = np.dot(points1_homog, H_12_initial.T)  # (500, 3)\n",
    "points1_transformed_initial /= points1_transformed_initial[:, 2:3]  # Normalize by the z-component\n",
    "initial_error = np.sum(np.linalg.norm(points1_transformed_initial[:, :2] - points2, axis=1))\n",
    "\n",
    "# Refined error\n",
    "points1_transformed_refined = np.dot(points1_homog, H_12_refined.T)  # (500, 3)\n",
    "points1_transformed_refined /= points1_transformed_refined[:, 2:3]  # Normalize by the z-component\n",
    "refined_error = np.sum(np.linalg.norm(points1_transformed_refined[:, :2] - points2, axis=1))\n",
    "\n",
    "# Print errors\n",
    "print(f\"Initial geometric error: {initial_error}\")\n",
    "print(f\"Refined geometric error: {refined_error}\")\n",
    "\n",
    "# Extract refined keypoints by applying the refined homography to points1\n",
    "points1_refined_homog = np.hstack((points1, np.ones((points1.shape[0], 1))))  # Convert to homogeneous coordinates\n",
    "points1_refined_transformed = np.dot(points1_refined_homog, H_12_refined.T)  # (500, 3)\n",
    "points1_refined_transformed /= points1_refined_transformed[:, 2:3]  # Normalize by the z-component\n",
    "points1_refined = points1_refined_transformed[:, :2]\n",
    "\n",
    "# Display points and refined points on images\n",
    "img1c = plt.imread('Data/llanes/llanes_a.jpg')  # Example, replace with actual image\n",
    "img2c = plt.imread('Data/llanes/llanes_b.jpg')  # Example, replace with actual image\n",
    "\n",
    "fig, ax = plt.subplots()  # image 1\n",
    "ax.imshow(img1c)\n",
    "ax.scatter(points1[:, 0], points1[:, 1], c='cyan', marker='+')\n",
    "ax.scatter(points1_refined[:, 0], points1_refined[:, 1], c='fuchsia', marker='+')\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(18.5, 10.5)\n",
    "plt.show()\n",
    "\n",
    "fig, ax = plt.subplots()  # image 2\n",
    "ax.imshow(img2c)\n",
    "ax.scatter(points2[:, 0], points2[:, 1], c='cyan', marker='+')\n",
    "ax.scatter(points1_refined[:, 0], points1_refined[:, 1], c='fuchsia', marker='+')\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(18.5, 10.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='color:Green'> - Refine the homography 23 with the Gold Standard algorithm and visualize the differences in the keypoint locations. </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "H_23_initial = H_23.copy()\n",
    "variables0 = H_23_initial.flatten()\n",
    "points2 = np.array([kp.pt for kp in kp2])\n",
    "points3 = np.array([kp.pt for kp in kp3])\n",
    "result = least_squares(geometric_error_terms, variables0, method='lm', args=([points2, points3], ))\n",
    "H_23_refined = result.x.reshape(3, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate and print the geometric error before and after the refinement\n",
    "# Initial error\n",
    "points2_homog = np.hstack((points2, np.ones((points2.shape[0], 1))))  # Convert to homogeneous coordinates (500, 3)\n",
    "points2_transformed_initial = np.dot(points2_homog, H_23_initial.T)  # (500, 3)\n",
    "points2_transformed_initial /= points2_transformed_initial[:, 2:3]  # Normalize by the z-component\n",
    "initial_error_23 = np.sum(np.linalg.norm(points2_transformed_initial[:, :2] - points3, axis=1))\n",
    "\n",
    "# Refined error\n",
    "points2_transformed_refined = np.dot(points2_homog, H_23_refined.T)  # (500, 3)\n",
    "points2_transformed_refined /= points2_transformed_refined[:, 2:3]  # Normalize by the z-component\n",
    "refined_error_23 = np.sum(np.linalg.norm(points2_transformed_refined[:, :2] - points3, axis=1))\n",
    "\n",
    "# Print errors for H_23\n",
    "print(f\"Initial geometric error for H_23: {initial_error_23}\")\n",
    "print(f\"Refined geometric error for H_23: {refined_error_23}\")\n",
    "\n",
    "# Extract refined keypoints by applying the refined homography to points2\n",
    "points2_refined_homog = np.hstack((points2, np.ones((points2.shape[0], 1))))  # Convert to homogeneous coordinates\n",
    "points2_refined_transformed = np.dot(points2_refined_homog, H_23_refined.T)  # (500, 3)\n",
    "points2_refined_transformed /= points2_refined_transformed[:, 2:3]  # Normalize by the z-component\n",
    "points2_refined = points2_refined_transformed[:, :2]\n",
    "\n",
    "# Display points and refined points on images\n",
    "img2c = plt.imread('Data/llanes/llanes_b.jpg')  # Example, replace with actual image\n",
    "img3c = plt.imread('Data/llanes/llanes_c.jpg')  # Example, replace with actual image\n",
    "\n",
    "# Plot results for image 2\n",
    "fig, ax = plt.subplots()  # image 2\n",
    "ax.imshow(img2c)\n",
    "ax.scatter(points2[:, 0], points2[:, 1], c='cyan', marker='+')\n",
    "ax.scatter(points2_refined[:, 0], points2_refined[:, 1], c='fuchsia', marker='+')\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(18.5, 10.5)\n",
    "plt.show()\n",
    "\n",
    "# Plot results for image 3\n",
    "fig, ax = plt.subplots()  # image 3\n",
    "ax.imshow(img3c)\n",
    "ax.scatter(points3[:, 0], points3[:, 1], c='cyan', marker='+')\n",
    "ax.scatter(points2_refined[:, 0], points2_refined[:, 1], c='fuchsia', marker='+')\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(18.5, 10.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='color:Green'> - Build mosaic with the refined homographies. </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corners = [-400, 1200, -100, 650] # corners of the canvas where the mosaic will be created\n",
    "\n",
    "img1c = cv2.imread('Data/llanes/llanes_a.jpg', cv2.IMREAD_COLOR)\n",
    "img2c = cv2.imread('Data/llanes/llanes_b.jpg', cv2.IMREAD_COLOR)\n",
    "img3c = cv2.imread('Data/llanes/llanes_c.jpg', cv2.IMREAD_COLOR)\n",
    "img1c = cv2.cvtColor(img1c, cv2.COLOR_BGR2RGB)\n",
    "img2c = cv2.cvtColor(img2c, cv2.COLOR_BGR2RGB)\n",
    "img3c = cv2.cvtColor(img3c, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "img1c_w = apply_H_fixed_image_size(img1c, H_12, corners) # complete the call to the function\n",
    "img2c_w = apply_H_fixed_image_size(img2c, np.eye(3), corners) # complete the call to the function\n",
    "img3c_w = apply_H_fixed_image_size(img3c, np.linalg.inv(H_23), corners) # complete the call to the function\n",
    "\n",
    "img_mosaic = np.maximum(img3c_w,np.maximum(img1c_w,img2c_w))\n",
    "plot_img(img_mosaic)\n",
    "fig = matplotlib.pyplot.gcf()\n",
    "fig.set_size_inches(18.5, 10.5)\n",
    "img_mosaic = cv2.cvtColor(img_mosaic, cv2.COLOR_RGB2BGR)\n",
    "cv2.imwrite('mosaic_llanes.png', img_mosaic) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corners = [-400, 1200, -100, 650] # corners of the canvas where the mosaic will be created\n",
    "\n",
    "img1c = cv2.imread('Data/llanes/llanes_a.jpg', cv2.IMREAD_COLOR)\n",
    "img2c = cv2.imread('Data/llanes/llanes_b.jpg', cv2.IMREAD_COLOR)\n",
    "img3c = cv2.imread('Data/llanes/llanes_c.jpg', cv2.IMREAD_COLOR)\n",
    "img1c = cv2.cvtColor(img1c, cv2.COLOR_BGR2RGB)\n",
    "img2c = cv2.cvtColor(img2c, cv2.COLOR_BGR2RGB)\n",
    "img3c = cv2.cvtColor(img3c, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "img1c_w = apply_H_fixed_image_size(img1c, H_12_refined, corners) # complete the call to the function\n",
    "img2c_w = apply_H_fixed_image_size(img2c, np.eye(3), corners) # complete the call to the function\n",
    "img3c_w = apply_H_fixed_image_size(img3c, np.linalg.inv(H_23_refined), corners) # complete the call to the function\n",
    "\n",
    "img_mosaic = np.maximum(img3c_w,np.maximum(img1c_w,img2c_w))\n",
    "plot_img(img_mosaic)\n",
    "fig = matplotlib.pyplot.gcf()\n",
    "fig.set_size_inches(18.5, 10.5)\n",
    "img_mosaic = cv2.cvtColor(img_mosaic, cv2.COLOR_RGB2BGR)\n",
    "cv2.imwrite('mosaic_llanes.png', img_mosaic) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **4. Application: Calibration with a planar pattern and augmented reality**\n",
    "\n",
    "As we have seen in class, we can calibrate a camera with a planar pattern with Zhang's algorithm. A key aspect of this algorithm is the estimation of a homography that relates a pair of images, in particular, the template image and an image of it taken with the camera we want to calibrate. Once the camera is calibrated and we have recovered the relative pose between the camera and the planar pattern we can properly insert a virtual object on top of the flat pattern in a way that it is consistent, in a perspective sense, with rest of the scene.\n",
    "\n",
    "### **4.1 Camera calibration**\n",
    "\n",
    "The following code calibrates a camera using N (where N greater or equal than three) views of the planar pattern. Most of the code is provided but there are parts you need to complete. These parts are indicated in green before the corresponding cell code.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read template image and calibration images\n",
    "template = cv2.imread('Data/calib/template.jpg',cv2.IMREAD_GRAYSCALE)\n",
    "images = []\n",
    "N = 3 # 3, 4, or 5\n",
    "for i in range(1,N+1):\n",
    "    m = cv2.imread(\"Data/calib/graffiti{0}.tif\".format(i),cv2.IMREAD_GRAYSCALE)\n",
    "    images.append(m)\n",
    "\n",
    "# Initiate ORB detector\n",
    "orb = cv2.ORB_create()\n",
    "# find the keypoints and descriptors with ORB\n",
    "kpt, dest = orb.detectAndCompute(template,None)\n",
    "kpi, desi = [], []\n",
    "for m in images:\n",
    "    kp, des = orb.detectAndCompute(m,None)\n",
    "    kpi.append(kp)\n",
    "    desi.append(des)\n",
    "\n",
    "\n",
    "# Keypoint matching and homography estimation\n",
    "bf = cv2.BFMatcher()\n",
    "H = []\n",
    "for i in range(N):\n",
    "    matches = bf.knnMatch(dest,desi[i],k=2)\n",
    "    # Apply ratio test\n",
    "    good_matches = []\n",
    "    for m,n in matches:\n",
    "        if m.distance < 0.75*n.distance:\n",
    "            good_matches.append([m])\n",
    "    \n",
    "    # Fit homography and remove outliers\n",
    "    points1 = []\n",
    "    points2 = []\n",
    "    for m in good_matches:\n",
    "        points1.append([kpt[m[0].queryIdx].pt[0], kpt[m[0].queryIdx].pt[1], 1])\n",
    "        points2.append([kpi[i][m[0].trainIdx].pt[0], kpi[i][m[0].trainIdx].pt[1], 1])\n",
    "    \n",
    "    points1 = np.asarray(points1)\n",
    "    points1 = points1.T\n",
    "    points2 = np.asarray(points2)\n",
    "    points2 = points2.T\n",
    "    \n",
    "    Hi, indices_inlier_matches = Ransac_DLT_homography(points1, points2, 3, 1000)\n",
    "    H.append(Hi)\n",
    "    \n",
    "    # Show inlier matches\n",
    "    inlier_matches = itemgetter(*indices_inlier_matches)(good_matches)\n",
    "    img_12 = cv2.drawMatchesKnn(template,kpt,images[i],kpi[i],inlier_matches,None,flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)\n",
    "    plt.imshow(img_12)\n",
    "    fig = matplotlib.pyplot.gcf()\n",
    "    fig.set_size_inches(18.5, 10.5)\n",
    "    plt.show()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='color:Green'> - Complete the code that computes the Image of the Absolute Conic. </span>\n",
    "\n",
    "<span style='color:Green'> - Complete the code that computes the matrix of internal parameters, K. </span>\n",
    "\n",
    "Note: there is a linalg.cholesky function both in numpy and scipy, you have to read the documentation of both and find out which is the proper one to use here.\n",
    "\n",
    "<span style='color:Green'> - In the report, make some comments related to the obtained internal camera parameters and also comment their relation to the image size. </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the Image of the Absolute Conic ...\n",
    "\n",
    "# Compute the matrix of internal parameters, K ...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='color:Green'> - Complete the calculation of r1, r2, and ti in the code below. </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute camera position and orientation\n",
    "import math\n",
    "R = []\n",
    "t = []\n",
    "P = []\n",
    "\n",
    "for i in range(N):\n",
    "    # compute r1, r2, and ti\n",
    "    h = H[i]\n",
    "    r1 = # complete ...\n",
    "    r2 = # complete ...\n",
    "    ti = # complete ...\n",
    "    \n",
    "    # Solve the scale ambiguity by forcing r1 and r2 to be unit vectors.\n",
    "    s = math.sqrt(np.linalg.norm(r1) * np.linalg.norm(r2)) * np.sign(ti[2])\n",
    "    r1 = r1 / s\n",
    "    r2 = r2 / s\n",
    "    ti = ti / s\n",
    "    t.append(ti)\n",
    "    Ri = np.array([r1, r2, np.cross(r1,r2)])\n",
    "    Ri = Ri.T\n",
    "    \n",
    "    # Ensure R is a rotation matrix\n",
    "    U, d, Vt = np.linalg.svd(Ri)\n",
    "    Ri = U @ np.identity(3) @ Vt\n",
    "    R.append(Ri)\n",
    "   \n",
    "    # Pi = K * [Ri ti]\n",
    "    A = np.zeros((3,4))\n",
    "    A[:3,:3] = Ri\n",
    "    A[:,3] = ti\n",
    "    Pi = K @ A\n",
    "    P.append(Pi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code (no need to be completed) draws the planar pattern and the N camera locations (position and orientation).\n",
    "\n",
    "<span style='color:Green'> - Take a look to the provided code for that and in the report explain how the optical center is computed. </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "from utils import plot_camera, plot_image_origin\n",
    "\n",
    "ny, nx = images[0].shape\n",
    "\n",
    "fig = go.Figure()\n",
    "for i in range(N):\n",
    "    plot_camera(P[i], nx, ny, fig, \"camera{0}\".format(i))\n",
    "\n",
    "plot_image_origin(nx, ny, fig, \"image\")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, we can draw a fixed camera and N planar patterns at different relative poses with respect to the camera.\n",
    "\n",
    "<span style='color:Green'> -Complete the function ' plot_image_Rt' in order to achieve that. Note: it may be useful to look at function 'plot_image_origin' in utils.py</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_image_Rt(R,t,w, h, fig, legend):\n",
    "    p1 = # to complete ...\n",
    "    p2 = # to complete ...\n",
    "    p3 = # to complete ...\n",
    "    p4 = # to complete ...\n",
    "\n",
    "    x = np.array([p1[0], p2[0], p3[0], p4[0], p1[0]])\n",
    "    y = np.array([p1[1], p2[1], p3[1], p4[1], p1[1]])\n",
    "    z = np.array([p1[2], p2[2], p3[2], p4[2], p1[2]])\n",
    "\n",
    "    fig.add_trace(go.Scatter3d(x=x, y=z, z=-y, mode='lines',name=legend))\n",
    "    \n",
    "    return\n",
    "\n",
    "\n",
    "fig = go.Figure()\n",
    "A = np.zeros((3,4))\n",
    "A[0,0]=A[1,1]=A[2,2]=1\n",
    "\n",
    "plot_camera(K@A, nx, ny, fig, \"camera\")\n",
    "for i in range(N):\n",
    "    plot_image_Rt(R[i], t[i], nx, ny, fig, \"image{0}\".format(i))\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4.2 OPTIONAL. Augmented reality**\n",
    "\n",
    "The following code (no need to be completed) draws a simple 3D virtual object (a cube) on top of the flat pattern.\n",
    "\n",
    "<span style='color:Green'> - Analyse the provided code and in the report explain how the virtual object is inserted in the image and why the camera view needs to be calibrated. </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Th, Tw = template.shape\n",
    "cube_corners = np.array([[0, 0, 0], [1, 0, 0], [1, 1, 0], [0, 1, 0], [0, 0, 0], [0, 0, 1], [1, 0, 1], [1, 1, 1], [0, 1, 1], [0, 0, 1], [0, 0, 0], [1, 0, 0], [1, 0, 1], [0, 0, 1], [0, 0, 0], [0, 1, 0], [1, 1, 0], [1, 1, 1], [0, 1, 1], [0, 1, 0]])\n",
    "\n",
    "import numpy.matlib\n",
    "offset = np.array([Tw/2, Th/2, -Tw/8])\n",
    "M = cube_corners.shape[0]\n",
    "X = (cube_corners - 0.5) * Tw/ 4 + np.matlib.repmat(offset, M, 1)\n",
    "\n",
    "X = X.T\n",
    "ones = np.ones(M)\n",
    "Xh = np.stack((X[0,:], X[1,:], X[2,:], ones), axis=0)\n",
    "\n",
    "line_color = (0, 255, 0)\n",
    "\n",
    "for i in range(N):\n",
    "    \n",
    "    xp = P[i]@Xh\n",
    "    xp = xp / xp[2,:]\n",
    "    xp = xp.astype(int)\n",
    "    \n",
    "    image = cv2.imread(\"Data/calib/graffiti{0}.tif\".format(i+1),cv2.IMREAD_COLOR)\n",
    "    image_gray = image\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    image_gray[:, :, 0] = gray[:, :]\n",
    "    image_gray[:, :, 1] = image_gray[:, :, 0]\n",
    "    image_gray[:, :, 2] = image_gray[:, :, 0]\n",
    "    for j in range(M-1):\n",
    "        image = cv2.line(image_gray, (xp[0,j],xp[1,j]), (xp[0,j+1],xp[1,j+1]), line_color, 4) \n",
    "    plt.imshow(image)\n",
    "    fig = matplotlib.pyplot.gcf()\n",
    "    fig.set_size_inches(18.5, 10.5)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **5. OPTIONAL. Application: Logo detection**\n",
    "\n",
    "<span style='color:Green'> - Detect the UPF logo in the two UPF images using the DLT algorithm (folder \"logos\").\n",
    "Interpret and comment the results. </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **6. OPTIONAL. Application: Logo replacement**\n",
    "\n",
    "<span style='color:Green'> - Replace the UPF logo by the master logo in one of the previous images using the DLT algorithm. </span>\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
